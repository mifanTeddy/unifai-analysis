import { Router, Request, Response, NextFunction } from "express";
import { z } from "zod";
import { v4 as uuidv4 } from "uuid";
import OpenAI from "openai";
import { HttpsProxyAgent } from "https-proxy-agent";
import { logger } from "../utils/logger";
import { dbService } from "../services/database";
import { unifaiService } from "../services/unifai";
import { AppError } from "../middleware/errorHandler";

const router: Router = Router();

/**
 * èŠå¤©å®Œæˆè¯·æ±‚éªŒè¯æ¨¡å¼
 */
const chatCompletionSchema = z.object({
  model: z.string().min(1, "æ¨¡å‹åç§°ä¸èƒ½ä¸ºç©º"),
  messages: z.array(z.any()).min(1, "æ¶ˆæ¯æ•°ç»„ä¸èƒ½ä¸ºç©º"),
  tools: z.array(z.any()).optional(),
  tool_choice: z
    .union([z.literal("auto"), z.literal("none"), z.object({})])
    .optional(),
  temperature: z.number().min(0).max(2).optional(),
  max_tokens: z.number().positive().optional(),
  stream: z.boolean().optional(),
  stop: z.union([z.string(), z.array(z.string())]).optional(),
  presence_penalty: z.number().min(-2).max(2).optional(),
  frequency_penalty: z.number().min(-2).max(2).optional(),
  top_p: z.number().min(0).max(1).optional(),
  n: z.number().positive().optional(),
  user: z.string().optional(),
});

/**
 * æ ¹æ®æ¨¡å‹é€‰æ‹©åˆé€‚çš„ OpenAI å®¢æˆ·ç«¯
 * @param model æ¨¡å‹åç§°
 * @returns OpenAI å®¢æˆ·ç«¯å®ä¾‹
 */
const getOpenAIClient = (model: string): OpenAI => {
  // é…ç½®ä»£ç†
  const proxyAgent = new HttpsProxyAgent(process.env.HTTPS_PROXY || process.env.HTTP_PROXY || "");

  const apiKey = process.env.OPENROUTER_API_KEY || 'sk-or-v1-dummy-key';

  // æ£€æµ‹ API å¯†é’¥æ ¼å¼
  if (apiKey.startsWith('sk-ant-')) {
    // å¦‚æœæ˜¯ Anthropic æ ¼å¼çš„å¯†é’¥ï¼Œç›´æ¥è°ƒç”¨ Anthropic API
    logger.info("ğŸ”‘ æ£€æµ‹åˆ° Anthropic API å¯†é’¥ï¼Œä½¿ç”¨ Anthropic API");
    return new OpenAI({
      apiKey: apiKey,
      baseURL: "https://api.anthropic.com/v1",
      httpAgent: proxyAgent,
      defaultHeaders: {
        'anthropic-version': '2023-06-01',
      },
    });
  } else {
    // ä½¿ç”¨ OpenRouter
    logger.info("ğŸ”‘ ä½¿ç”¨ OpenRouter API");
    return new OpenAI({
      apiKey: apiKey,
      baseURL: "https://openrouter.ai/api/v1",
      httpAgent: proxyAgent,
    });
  }
};

/**
 * è®¡ç®— Token è´¹ç”¨
 * @param model æ¨¡å‹åç§°
 * @param promptTokens æç¤ºè¯ Token æ•°
 * @param completionTokens å®Œæˆå“åº” Token æ•°
 * @returns è´¹ç”¨ï¼ˆUSDï¼‰
 */
const calculateCost = (
  model: string,
  promptTokens: number,
  completionTokens: number,
): number => {
  const pricing: { [key: string]: { prompt: number; completion: number } } = {
    "gpt-4": { prompt: 0.03 / 1000, completion: 0.06 / 1000 },
    "gpt-3.5-turbo": { prompt: 0.001 / 1000, completion: 0.002 / 1000 },
    "claude-3-opus": { prompt: 0.015 / 1000, completion: 0.075 / 1000 },
    "claude-3-sonnet": { prompt: 0.003 / 1000, completion: 0.015 / 1000 },
    "gemini-pro": { prompt: 0.000125 / 1000, completion: 0.000375 / 1000 },
  };

  const modelPricing = pricing[model] || pricing["gpt-3.5-turbo"];
  return (
    promptTokens * modelPricing.prompt +
    completionTokens * modelPricing.completion
  );
};

/**
 * èŠå¤©å®Œæˆæ¥å£
 * æ”¯æŒæµå¼å’Œéæµå¼å“åº”ï¼ŒåŒ…å«å·¥å…·è°ƒç”¨å¾ªç¯
 */
router.post(
  "/completions",
  async (req: Request, res: Response, next: NextFunction) => {
    const startTime = Date.now();
    let dbRequest: any;

    try {
      // éªŒè¯è¯·æ±‚æ•°æ®
      const validatedData = chatCompletionSchema.parse(req.body);
      const {
        model,
        messages,
        stream = false,
        tools: userTools,
        ...otherParams
      } = validatedData;

      // ç”Ÿæˆè¯·æ±‚ID
      const requestId = uuidv4();

      // è®°å½•è¯·æ±‚åˆ°æ•°æ®åº“
      dbRequest = await dbService.createRequest({
        id: requestId,
        userId: validatedData.user,
        model,
        messages: JSON.stringify(messages),
        tools: userTools ? JSON.stringify(userTools) : undefined,
        stream,
      });

      logger.info("ğŸš€ å¤„ç†èŠå¤©å®Œæˆè¯·æ±‚", {
        requestId,
        model,
        messageCount: messages.length,
        stream,
        hasTools: !!userTools,
      });

      // è·å– UnifAI å·¥å…·ï¼ˆå¦‚æœç”¨æˆ·æœªæä¾›å·¥å…·ï¼‰
      const finalTools = userTools || (await unifaiService.getTools());

      // åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯
      const client = getOpenAIClient(model);

      // å‡†å¤‡å¯¹è¯æ¶ˆæ¯å’Œå“åº”è¿½è¸ª
      let conversationMessages = [...messages];
      const allResponses: any[] = [];
      const toolNamesUsed: string[] = [];
      let totalTokens = { prompt: 0, completion: 0, total: 0 };

      // å¤„ç†æµå¼ vs éæµå¼å“åº”
      if (stream) {
        res.setHeader("Content-Type", "text/event-stream");
        res.setHeader("Cache-Control", "no-cache");
        res.setHeader("Connection", "keep-alive");
        res.setHeader("Access-Control-Allow-Origin", "*");

        // å‘é€åˆå§‹æ•°æ®å—
        res.write(
          `data: ${JSON.stringify({
            id: requestId,
            object: "chat.completion.chunk",
            created: Math.floor(Date.now() / 1000),
            model,
            choices: [
              {
                index: 0,
                delta: { role: "assistant", content: "" },
                finish_reason: null,
              },
            ],
          })}\n\n`,
        );
      }

      // å¯¹è¯å¾ªç¯ - ç»§ç»­ç›´åˆ°æ²¡æœ‰å·¥å…·è°ƒç”¨
      while (true) {
        try {
          // è½¬æ¢æ¨¡å‹åç§°ï¼ˆå¦‚æœç›´æ¥è°ƒç”¨ Anthropic APIï¼‰
          let actualModel = model;
          const apiKey = process.env.OPENROUTER_API_KEY || 'sk-or-v1-dummy-key';
          if (apiKey.startsWith('sk-ant-') && model.startsWith('anthropic/')) {
            actualModel = model.replace('anthropic/', '');
            logger.info("ğŸ”„ è½¬æ¢æ¨¡å‹åç§°", { original: model, actual: actualModel });
          }

          // å‘å¤§æ¨¡å‹å‘é€è¯·æ±‚
          const response = await client.chat.completions.create({
            model: actualModel,
            messages: conversationMessages as any,
            tools: finalTools,
            stream: false,
            temperature: otherParams.temperature,
            max_tokens: otherParams.max_tokens,
            stop: otherParams.stop,
            presence_penalty: otherParams.presence_penalty,
            frequency_penalty: otherParams.frequency_penalty,
            top_p: otherParams.top_p,
            n: otherParams.n,
            user: otherParams.user,
          });

          logger.info("ğŸ¤– LLM å“åº”:", { response: response.choices[0] });

          const choice = response.choices[0];
          if (!choice) {
            const error = new Error("æ¨¡å‹æœªè¿”å›å“åº”") as AppError;
            error.statusCode = 500;
            error.code = "model_error";
            throw error;
          }

          const assistantMessage = choice.message;

          // ç´¯è®¡Tokenä½¿ç”¨é‡
          if (response.usage) {
            totalTokens.prompt += response.usage.prompt_tokens || 0;
            totalTokens.completion += response.usage.completion_tokens || 0;
            totalTokens.total += response.usage.total_tokens || 0;
          }

          // è®°å½•å“åº”
          allResponses.push({
            content: assistantMessage.content,
            toolCalls: assistantMessage.tool_calls,
            finishReason: choice.finish_reason,
          });

          // å°†åŠ©æ‰‹æ¶ˆæ¯æ·»åŠ åˆ°å¯¹è¯ä¸­
          conversationMessages.push(assistantMessage);

          // å¦‚æœå­˜åœ¨å·¥å…·è°ƒç”¨ï¼Œåˆ™å¤„ç†å·¥å…·
          if (
            assistantMessage.tool_calls &&
            assistantMessage.tool_calls.length > 0
          ) {
            logger.info("ğŸ”§ å¤„ç†å·¥å…·è°ƒç”¨", {
              requestId,
              toolCallCount: assistantMessage.tool_calls.length,
            });

            // æå–å·¥å…·åç§°
            const currentToolNames = assistantMessage.tool_calls.map(
              (tc) => tc.function.name,
            );
            toolNamesUsed.push(...currentToolNames);

            // ä½¿ç”¨ UnifAI è°ƒç”¨å·¥å…·
            const toolCallStart = Date.now();
            const toolResults = await unifaiService.callTools(
              assistantMessage.tool_calls,
            );
            const toolCallDuration = Date.now() - toolCallStart;

            // å°†å·¥å…·ç»“æœæ·»åŠ åˆ°å¯¹è¯ä¸­
            conversationMessages.push(...toolResults);

            // è®°å½•å·¥å…·è°ƒç”¨åˆ°æ•°æ®åº“
            for (const toolCall of assistantMessage.tool_calls) {
              await dbService.createToolCall({
                requestId,
                toolName: toolCall.function.name,
                toolId: toolCall.id,
                arguments: JSON.stringify(toolCall.function.arguments),
                result:
                  toolResults.find((r) => r.tool_call_id === toolCall.id)
                    ?.content || undefined,
                success: true,
                executionTime: toolCallDuration,
              });
            }

            if (stream) {
              // åœ¨æµä¸­å‘é€å·¥å…·è°ƒç”¨ä¿¡æ¯
              res.write(
                `data: ${JSON.stringify({
                  id: requestId,
                  object: "chat.completion.chunk",
                  created: Math.floor(Date.now() / 1000),
                  model,
                  choices: [
                    {
                      index: 0,
                      delta: {
                        content: `\n[ä½¿ç”¨å·¥å…·: ${currentToolNames.join(", ")}]\n`,
                      },
                      finish_reason: null,
                    },
                  ],
                })}\n\n`,
              );
            }

            // ç»§ç»­å¯¹è¯å¾ªç¯
            continue;
          } else {
            // æ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œç»“æŸå¾ªç¯
            if (stream && assistantMessage.content) {
              // å‘é€æœ€ç»ˆå†…å®¹
              res.write(
                `data: ${JSON.stringify({
                  id: requestId,
                  object: "chat.completion.chunk",
                  created: Math.floor(Date.now() / 1000),
                  model,
                  choices: [
                    {
                      index: 0,
                      delta: { content: assistantMessage.content },
                      finish_reason: choice.finish_reason,
                    },
                  ],
                })}\n\n`,
              );
            }
            break;
          }
        } catch (apiError: any) {
          logger.error("ğŸš¨ API è°ƒç”¨å¤±è´¥", {
            requestId,
            error: apiError.message,
            status: apiError.status,
            model,
            apiKey: process.env.OPENROUTER_API_KEY ? 'configured' : 'missing'
          });

          // å¦‚æœæ˜¯è®¤è¯é”™è¯¯ï¼Œè¿”å›æ›´å‹å¥½çš„é”™è¯¯ä¿¡æ¯
          if (apiError.status === 401) {
            const error = new Error("API è®¤è¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥ OPENROUTER_API_KEY é…ç½®") as AppError;
            error.statusCode = 401;
            error.code = "auth_error";
            throw error;
          }

          throw apiError;
        }
      }

      // è®¡ç®—å“åº”æ—¶é—´å’Œè´¹ç”¨
      const responseTime = Date.now() - startTime;
      const cost = calculateCost(
        model,
        totalTokens.prompt,
        totalTokens.completion,
      );

      // æ„å»ºæœ€ç»ˆå“åº”
      const finalResponse = {
        id: requestId,
        object: "chat.completion",
        created: Math.floor(startTime / 1000),
        model,
        choices: [
          {
            index: 0,
            message: {
              role: "assistant" as const,
              content: allResponses
                .map((r) => r.content)
                .filter(Boolean)
                .join(""),
              tool_calls: allResponses.flatMap((r) => r.toolCalls || []),
            },
            finish_reason:
              allResponses[allResponses.length - 1]?.finishReason || "stop",
          },
        ],
        usage: {
          prompt_tokens: totalTokens.prompt,
          completion_tokens: totalTokens.completion,
          total_tokens: totalTokens.total,
        },
        tools_used: toolNamesUsed,
        response_time_ms: responseTime,
      };

      // ä¿å­˜å“åº”åˆ°æ•°æ®åº“
      await dbService.createResponse({
        id: uuidv4(),
        requestId,
        content: JSON.stringify(finalResponse),
        toolCalls:
          toolNamesUsed.length > 0 ? JSON.stringify(toolNamesUsed) : undefined,
        finishReason: finalResponse.choices[0].finish_reason,
        responseTime,
      });

      // ä¿å­˜Tokenä½¿ç”¨è®°å½•
      await dbService.createTokenUsage({
        requestId,
        model,
        promptTokens: totalTokens.prompt,
        completionTokens: totalTokens.completion,
        totalTokens: totalTokens.total,
        cost,
      });

      logger.info("âœ… èŠå¤©å®Œæˆè¯·æ±‚å¤„ç†æˆåŠŸ", {
        requestId,
        responseTime,
        totalTokens: totalTokens.total,
        toolsUsed: toolNamesUsed.length,
        cost: cost.toFixed(6),
      });

      // å‘é€å“åº”
      if (stream) {
        // å‘é€æµç»“æŸæ ‡è®°
        res.write(
          `data: ${JSON.stringify({
            id: requestId,
            object: "chat.completion.chunk",
            created: Math.floor(Date.now() / 1000),
            model,
            choices: [
              {
                index: 0,
                delta: {},
                finish_reason: finalResponse.choices[0].finish_reason,
              },
            ],
          })}\n\n`,
        );
        res.write("data: [DONE]\n\n");
        res.end();
      } else {
        res.json(finalResponse);
      }
    } catch (error) {
      logger.error("âŒ èŠå¤©å®Œæˆè¯·æ±‚å¤„ç†å¤±è´¥", {
        error: error instanceof Error ? error.message : String(error),
        stack: error instanceof Error ? error.stack : undefined,
        requestBody: req.body,
      });

      // å¦‚æœå·²ç»åˆ›å»ºäº†è¯·æ±‚è®°å½•ï¼Œæ›´æ–°ä¸ºå¤±è´¥çŠ¶æ€
      if (dbRequest) {
        try {
          await dbService.createResponse({
            id: uuidv4(),
            requestId: dbRequest.id,
            content: JSON.stringify({
              error: error instanceof Error ? error.message : String(error),
            }),
            finishReason: "error",
            responseTime: Date.now() - startTime,
          });
        } catch (dbError) {
          logger.error("ä¿å­˜é”™è¯¯å“åº”å¤±è´¥", dbError);
        }
      }

      next(error);
    }
  },
);

export { router as chatRouter };
